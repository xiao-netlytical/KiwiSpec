define conn_path=../sample_data/zeek,
output_path=../sample_data/result,application_path=../rules/application


READ output_path/clean_ip_to_servers.json AS srvs; 
output_path/clean_server_to_ips.json AS ips;
conn_path/conn.json AS flows; 
application_path/app_protos.json as app_protos;
application_path/proto_desciption.json as proto_disc;
output_path/clean_server_to_ips.json as ips;
application_path/application_logic.json as application

# application classification logic is defined in application_logic.json file
# here is an example of the definition:
#"unit(proto ==\"udp\" and port==1812 or proto ==\"udp\" and port==1645) and 
#unit(proto ==\"udp\" and port==1812 or proto ==\"udp\" and port==1646) and 
#unit(proto ==\"udp\" and port==1813 or proto ==\"udp\" and port==1645) and 
#unit(proto ==\"udp\" and port==1813 or proto ==\"udp\" and port==1646)"
# The mapping of an IP to the application servers are calculated.

create {ip1:out_port} as r_src; {ip2:in_port} as r_dst 
var i select
    flows[i]["id.orig_h"] as ip1;
    collect set((flows[i]["proto"], flows[i]["id.resp_p"])) group by ip1 as out_port;
    flows[i]["id.resp_h"] as ip2;
    collect set((flows[i]["proto"], flows[i]["id.resp_p"])) group by ip2 as in_port;
    where flows[i]["conn_state"] in ["OTH", "SF", "S1", "S2", "S3", "RSTO", "RSTR"]

create {ip:apps} as r 
var ip, k, x, y select 
    r_dst[ip] as in_p_set; 
    r_src[ip | []] as out_p_set; 
    collect eval(application[k]["lookup_condition"]: proto=in_p_set[x][0], port=in_p_set[x][1], out_proto =out_p_set[y][0], out_port=out_p_set[y][1]) group by x,y as app_condition;
    collect list(application[k]["app_name"]) where app_condition group by ip as apps

WRITE output_path/ip_apps_t.json from r

# This spec strip of the IP to empty server list mapping
create {i:result} as r1
var i select
	r[i] as result;
	where result

WRITE output_path/ip_apps.json from r1

####################
READ conn_path/conn.json AS flows; output_path/ip_to_servers.json AS srv
create   [path_recording] as result
var i, j select
    flows[i]["id.orig_h"] AS s_ip_1;
    flows[i]["id.resp_h"] AS d_ip_1;
    flows[j]["id.orig_h"] AS s_ip_2;
    flows[j]["id.resp_h"] AS d_ip_2;
    collect set ((s_ip_1, d_ip_1)) where d_ip_1 == s_ip_2 extend by (s_ip_2, d_ip_2) as path_recording;
where flows[i]["id.resp_p"] == 445; flows[j]["id.resp_p"] == 445
WRITE output_path/path_recording.json FROM result


########
#every one minute sampling of a five minute interval, get DNS request count for per window and per source address
read conn_path/conn.json as flows
create {window_start: {dns_src: cnt}}  as r
var i,j select
    flows[i]["id.orig_h"] as dns_src;
    int(epoch_time(flows[i]["ts"])/60) as window_start;
    count distinct(j from flows[j]) group by dns_src, window_start as cnt;
where flows[i]["id.resp_p"] == 53; flows[j]["id.resp_p"] == 53; flows[j]["id.orig_h"] == dns_src;
int(epoch_time(flows[j]["ts"])/60) >= window_start and int(epoch_time(flows[j]["ts"])/60) < window_start + 5
write output_path/5_min_dns_request.json from r






